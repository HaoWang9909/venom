{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/end2end/lib/python3.12/site-packages/torch/_utils.py:842: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/root/miniconda3/envs/end2end/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:366: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/end2end/lib/python3.12/inspect.py:586: UserWarning: The is_traceable field on torch.autograd.Function is deprecated and will be removed in PyTorch 2.4.\n",
      "  value = getter(object, key)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://spcl.github.io/dace-webclient/dist/sdfv.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statistics\n",
    "import subprocess\n",
    "import ctypes\n",
    "\n",
    "import sten\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import timeit\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from grouped_nmv_tensor import SrNMTensor, nm_vector_mask_sparsify\n",
    "\n",
    "import spatha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMVectorSparsifier:\n",
    "    # 类的构造函数，初始化实例变量。\n",
    "    def __init__(self, n, m, tileM):\n",
    "        self.n = n          # n 是用于某些稀疏操作的参数，具体含义根据上下文而定\n",
    "        self.m = m          # m 是分块大小或其他相关操作的参数\n",
    "        self.tileM = tileM  # tileM 是用于分块的尺寸，影响最终稀疏矩阵的结构\n",
    "\n",
    "    # 特殊方法__call__使得实例可以像函数那样被调用\n",
    "    def __call__(self, tensor, grad_fmt=None):\n",
    "        # uncomment to use magnitude-pruning -> mask, columns\n",
    "        # mask, columns = nm_vector_mask_sparsify(tensor, sparsifier.n, sparsifier.m, sparsifier.tileM)\n",
    "\n",
    "        # uncomment to use random pruning (cuSparseLt-like approach) -> mask, columns\n",
    "        \n",
    "        # 以下是处理张量以生成稀疏结构的过程\n",
    "        # 计算张量的行和列数\n",
    "        nrows, ncols = tensor.shape\n",
    "\n",
    "        # 创建存储列索引的张量，初始为全0，其大小由原张量的行数和列数决定，并按tileM和m进行调整\n",
    "        columns = torch.zeros(nrows//self.tileM, ncols//self.m*4, dtype=torch.int32)\n",
    "        # 重新形状并添加特定的列索引，这里加上了[0,1,2,3]，目的是为每个分块创建重复的模式\n",
    "        columns = columns.reshape((-1,4)) + torch.tensor([0,1,2,3], dtype=torch.int32)\n",
    "        # 再次调整形状，确保columns的形状与处理后的张量结构相匹配\n",
    "        columns = columns.reshape((nrows//self.tileM, ncols//self.m*4))\n",
    "\n",
    "        # 创建掩码张量，初始为全0，其形状与输入张量相同\n",
    "        mask = torch.zeros(tensor.shape, dtype=tensor.dtype)\n",
    "        # 创建一个小的模式掩码，并将其重复以填充整个掩码张量\n",
    "        m = torch.cat( (torch.tensor([1,0,1,0]), torch.zeros(self.m-4)), 0 )\n",
    "        # 通过广播添加模式掩码m到每个块\n",
    "        mask = mask.reshape(-1, self.tileM, self.m) + m\n",
    "        # 恢复掩码的原始形状以匹配输入张量\n",
    "        mask = mask.reshape(tensor.shape)\n",
    "\n",
    "        # 使用sten库创建一个稀疏张量包装器，这个稀疏张量基于之前创建的mask和columns\n",
    "        sparse_mtx = sten.SparseTensorWrapper.wrapped_from_dense(\n",
    "            SrNMTensor(self.n, self.m, self.tileM, tensor, mask, columns, tensor.device),\n",
    "            tensor,\n",
    "            grad_fmt,\n",
    "        )\n",
    "\n",
    "        # 返回处理后的稀疏矩阵对象\n",
    "        return sparse_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成一个4096x2048的随机张量\n",
    "torch.manual_seed(0)\n",
    "origin_weight = torch.rand((4096, 2048), dtype=torch.float32)\n",
    "#将w移动到cuda上使用半精度浮点数\n",
    "original_weight = origin_weight.cuda().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = NMVectorSparsifier(n, m, v)(original_weight).wrapped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.4963, 0.0885, 0.2386,  ..., 0.6001, 0.4131, 0.2450], device='cuda:0',\n",
       "       dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.nn.Parameter(w.values)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2,  ..., 1, 2, 3],\n",
       "        [0, 1, 2,  ..., 1, 2, 3],\n",
       "        [0, 1, 2,  ..., 1, 2, 3],\n",
       "        ...,\n",
       "        [0, 1, 2,  ..., 1, 2, 3],\n",
       "        [0, 1, 2,  ..., 1, 2, 3],\n",
       "        [0, 1, 2,  ..., 1, 2, 3]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = w.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMVectorSparsifier:\n",
    "    # 类的构造函数，初始化实例变量。\n",
    "    def __init__(self, n, m, tileM):\n",
    "        self.n = n          # n 是用于某些稀疏操作的参数，具体含义根据上下文而定\n",
    "        self.m = m          # m 是分块大小或其他相关操作的参数\n",
    "        self.tileM = tileM  # tileM 是用于分块的尺寸，影响最终稀疏矩阵的结构\n",
    "\n",
    "    # 特殊方法__call__使得实例可以像函数那样被调用\n",
    "    def __call__(self, tensor, grad_fmt=None):\n",
    "        # uncomment to use magnitude-pruning -> mask, columns\n",
    "        # mask, columns = nm_vector_mask_sparsify(tensor, sparsifier.n, sparsifier.m, sparsifier.tileM)\n",
    "\n",
    "        # uncomment to use random pruning (cuSparseLt-like approach) -> mask, columns\n",
    "        \n",
    "        # 以下是处理张量以生成稀疏结构的过程\n",
    "        # 计算张量的行和列数\n",
    "        nrows, ncols = tensor.shape\n",
    "\n",
    "        # 创建存储列索引的张量，初始为全0，其大小由原张量的行数和列数决定，并按tileM和m进行调整\n",
    "        columns = torch.zeros(nrows//self.tileM, ncols//self.m*4, dtype=torch.int32)\n",
    "        # 重新形状并添加特定的列索引，这里加上了[0,1,2,3]，目的是为每个分块创建重复的模式\n",
    "        columns = columns.reshape((-1,4)) + torch.tensor([0,1,2,3], dtype=torch.int32)\n",
    "        # 再次调整形状，确保columns的形状与处理后的张量结构相匹配\n",
    "        columns = columns.reshape((nrows//self.tileM, ncols//self.m*4))\n",
    "\n",
    "        # 创建掩码张量，初始为全0，其形状与输入张量相同\n",
    "        mask = torch.zeros(tensor.shape, dtype=tensor.dtype)\n",
    "        # 创建一个小的模式掩码，并将其重复以填充整个掩码张量\n",
    "        m = torch.cat( (torch.tensor([1,0,1,0]), torch.zeros(self.m-4)), 0 )\n",
    "        # 通过广播添加模式掩码m到每个块\n",
    "        mask = mask.reshape(-1, self.tileM, self.m) + m\n",
    "        # 恢复掩码的原始形状以匹配输入张量\n",
    "        mask = mask.reshape(tensor.shape)\n",
    "\n",
    "        # 使用sten库创建一个稀疏张量包装器，这个稀疏张量基于之前创建的mask和columns\n",
    "        sparse_mtx = sten.SparseTensorWrapper.wrapped_from_dense(\n",
    "            SrNMTensor(self.n, self.m, self.tileM, tensor, mask, columns, tensor.device),\n",
    "            tensor,\n",
    "            grad_fmt,\n",
    "        )\n",
    "\n",
    "        # 返回处理后的稀疏矩阵对象\n",
    "        return sparse_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_dense_mul_dispatch(sparse_values, sparse_indices, sparse_metadata, dense, nrows_sp, ncols_sp, ncols_d, m, n, v, nnz, bias):\n",
    "\n",
    "    dense_ = dense.contiguous()\n",
    "\n",
    "    output = spatha.spmm(sparse_metadata,  # metadata\n",
    "                          sparse_indices,   # indices\n",
    "                          sparse_values,    # values\n",
    "                          dense_,           # rhs_matrix\n",
    "                          bias,\n",
    "                          nrows_sp,         # A_num_rows\n",
    "                          ncols_sp,         # A_num_cols\n",
    "                          ncols_d,          # B_num_cols\n",
    "                          v,                # vec_length\n",
    "                          n,                # n\n",
    "                          m,                # m\n",
    "                          nnz,              # nnz\n",
    "                          0,                # seed\n",
    "                          32,               # mbrow\n",
    "                          4                 # brow\n",
    "                          )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrnmSpmm(torch.nn.Module):\n",
    "    def __init__(self, original: torch.nn.Linear):\n",
    "        super().__init__()\n",
    "        self.bias = original.bias\n",
    "\n",
    "        # Convert weights from original module to SrNM\n",
    "        w = NMVectorSparsifier(n, m, v)(original.weight).wrapped_tensor\n",
    "\n",
    "        self.values = torch.nn.Parameter(w.values)\n",
    "        #self.columns = self.register_buffer('columns', w.columns)\n",
    "        self.columns = w.columns\n",
    "        self.metadata = w.metadata\n",
    "\n",
    "        self.nrows_sp = w.nrows\n",
    "        self.ncols_sp = w.ncols\n",
    "        self.nnz      = w.nnz\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        flattened_input = torch.flatten(input, start_dim=0, end_dim=-2)\n",
    "\n",
    "        ncols_d  = flattened_input.T.shape[1]\n",
    "        DM, _    = flattened_input.shape\n",
    "\n",
    "        output = sparse_dense_mul_dispatch(self.values, self.columns, self.metadata, flattened_input.T, self.nrows_sp, self.ncols_sp,\n",
    "                                           ncols_d, m, n, v, self.nnz, self.bias)\n",
    "        output = output.reshape((*input.shape[0:-1], -1))[..., :DM]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_time(name, data, number):\n",
    "    for d in data:\n",
    "        time_ms = d / number * 1000\n",
    "        #print(f'n {n} m {m} format {name} time_ms {time_ms:.3f}')\n",
    "    ds = [(d / number * 1000) for d in data]\n",
    "    mean = statistics.mean(ds)\n",
    "    median = statistics.median(ds)\n",
    "    std = statistics.stdev(ds)\n",
    "\n",
    "    if name == \"n:m\":\n",
    "        cfg = str(n)+\",\"+str(m)+\",\"\n",
    "    else:\n",
    "        cfg = \"0,0,\"\n",
    "    print(\n",
    "        \"0,\"+cfg+str(v)+\",\"+str(mean)+\",\"+str(median)+\",\"+str(std)+\",\"+str(len(ds))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_spmm(mod, weights_to_sparsify):\n",
    "    if isinstance(mod, torch.nn.Linear):\n",
    "        return SrnmSpmm(mod)\n",
    "\n",
    "    for name, m in mod.named_children():\n",
    "        if isinstance(m, SrnmSpmm):\n",
    "            continue\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            setattr(mod, name, SrnmSpmm(m))\n",
    "        elif m is not mod:\n",
    "            linear_to_spmm(m, weights_to_sparsify)\n",
    "\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder_layer_prototype(num_repeats, number):\n",
    "    # 加载原始的BERT大模型\n",
    "    model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-large-uncased')\n",
    "\n",
    "    # 加载第二个BERT大模型，并转移到CUDA设备上，使用半精度浮点数(half precision)进行计算以提高性能\n",
    "    model2 = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-large-uncased').to(device='cuda:0').half()\n",
    "\n",
    "    # 生成一个随机整数输入，大小为32x512，用于模型输入\n",
    "    input = torch.randint(low=0, high=100, size=(32, 512))\n",
    "\n",
    "    # 生成一个列表，包含模型中所有线性层（Linear layers）的权重，这些权重将被转换为稀疏格式\n",
    "    weights_to_sparsify = [\n",
    "        module\n",
    "        for module_name, module in model.named_modules()\n",
    "        if (\n",
    "            isinstance(module, torch.nn.modules.linear.Linear)\n",
    "            and \"encoder.layer\" in module_name\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # 把模型和输入都转移到CUDA设备上，并使用半精度浮点数进行处理\n",
    "    model = model.to(device='cuda:0').half()\n",
    "    input = input.to(device='cuda:0')\n",
    "\n",
    "    # 将选定的权重转换为稀疏格式，并创建一个新的稀疏模型\n",
    "    sparse_model = linear_to_spmm(model, weights_to_sparsify)\n",
    "\n",
    "    # 执行模型一次，通常用于预热缓存\n",
    "    output = sparse_model(input)\n",
    "\n",
    "    # 如果命令行参数指定进行性能分析\n",
    "    if args.profile:\n",
    "        # 开启一个性能分析会话，记录CPU和CUDA的活动\n",
    "        with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, with_stack=True) as prof:\n",
    "            with record_function(\"model_inference\"):\n",
    "                # 执行模型推理，记录相关数据\n",
    "                output = sparse_model(input)\n",
    "        # 导出分析数据\n",
    "        prof.export_stacks(\"/tmp/profiler_stacks.txt\", \"self_cuda_time_total\")\n",
    "        prof.export_chrome_trace(\"trace_sparse.json\")\n",
    "        print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=15))\n",
    "\n",
    "        # 重复上述过程，但是这次使用密集模型\n",
    "        with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, with_stack=True) as prof:\n",
    "            with record_function(\"model_inference\"):\n",
    "                output = model2(input)\n",
    "        prof.export_stacks(\"/tmp/profiler_stacks_dense.txt\", \"self_cuda_time_total\")\n",
    "        prof.export_chrome_trace(\"trace_dense.json\")\n",
    "        print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=15))\n",
    "        exit()\n",
    "\n",
    "    # 使用timeit库，重复执行密集模型10次作为预热，然后进行正式的性能测试\n",
    "    timeit.repeat('output = model2(input)', repeat=10, number=number, globals=locals())\n",
    "    dense_times = timeit.repeat('output = model2(input)', repeat=num_repeats, number=number, globals=locals())\n",
    "    report_time('dense', dense_times, number)\n",
    "\n",
    "    # 对稀疏模型进行同样的预热和性能测试\n",
    "    timeit.repeat('output = sparse_model(input)', repeat=10, number=number, globals=locals())\n",
    "    sparse_times = timeit.repeat('output = sparse_model(input)', repeat=num_repeats, number=number, globals=locals())\n",
    "    report_time('n:m', sparse_times, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fb51f328500>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch. set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0,0,64,28.492342207270365,28.310824069194496,0.7472337186168171,30\n",
      "0,2,8,64,56.45544687286019,56.43744091503322,0.9001977038644426,30\n"
     ]
    }
   ],
   "source": [
    "transformer_encoder_layer_prototype(num_repeats=30, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end2end",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
